# Agent Monitoring Platform

A comprehensive monitoring and evaluation platform for AI agents with real-time telemetry, performance evaluation pipeline, and advanced data engineering capabilities.

## ğŸ¯ Platform Overview

The Agent Monitoring Platform provides a production-ready solution for:

- **Real-time Telemetry**: Capture and stream agent metrics, performance data, and system health
- **Evaluation Pipeline**: Automated benchmarking, quality assessment, and performance regression detection
- **Data Engineering**: ETL pipelines, data warehousing, analytics, and reporting
- **Dashboard & Analytics**: Visual monitoring with Streamlit and advanced analytics
- **Agent Registry**: Track agent versions, capabilities, and dependencies
- **Alert System**: Real-time alerts for anomalies and performance issues

## ğŸ“ Project Structure

```
agent_monitoring_platform/
â”œâ”€â”€ README.md                          # This file
â”œâ”€â”€ ARCHITECTURE.md                    # System architecture overview
â”œâ”€â”€ requirements.txt                   # Python dependencies
â”œâ”€â”€ setup.py                          # Package setup
â”‚
â”œâ”€â”€ telemetry/                        # Real-time telemetry collection
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ collector.py                  # Base telemetry collector
â”‚   â”œâ”€â”€ metrics.py                    # Metrics definitions
â”‚   â”œâ”€â”€ events.py                     # Event schema and handlers
â”‚   â”œâ”€â”€ exporters.py                  # Export to various backends
â”‚   â”œâ”€â”€ agent_tracer.py              # Agent execution tracing
â”‚   â””â”€â”€ performance_monitor.py        # Real-time performance monitoring
â”‚
â”œâ”€â”€ eval_pipeline/                    # Evaluation and benchmarking
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ base_evaluator.py            # Base evaluator class
â”‚   â”œâ”€â”€ quality_metrics.py            # Quality assessment metrics
â”‚   â”œâ”€â”€ performance_metrics.py        # Performance benchmarks
â”‚   â”œâ”€â”€ regression_detector.py        # Performance regression detection
â”‚   â”œâ”€â”€ benchmark_suite.py            # Benchmark execution engine
â”‚   â”œâ”€â”€ result_aggregator.py          # Aggregate and analyze results
â”‚   â””â”€â”€ comparator.py                 # Compare agent versions
â”‚
â”œâ”€â”€ data_engineering/                 # Data pipelines and warehousing
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ database_manager.py           # SQLite/PostgreSQL management
â”‚   â”œâ”€â”€ etl_pipeline.py               # ETL processing
â”‚   â”œâ”€â”€ data_models.py                # SQLAlchemy ORM models
â”‚   â”œâ”€â”€ analytics_engine.py           # Analytics and aggregations
â”‚   â”œâ”€â”€ data_export.py                # Export functionality
â”‚   â””â”€â”€ schema_manager.py             # Database schema management
â”‚
â”œâ”€â”€ agent_registry/                   # Agent management
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ registry.py                   # Agent registry
â”‚   â”œâ”€â”€ agent_metadata.py             # Agent metadata models
â”‚   â””â”€â”€ version_manager.py            # Version tracking
â”‚
â”œâ”€â”€ alerting/                         # Alert and notification system
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ alert_manager.py              # Alert management
â”‚   â”œâ”€â”€ rules_engine.py               # Alert rules
â”‚   â”œâ”€â”€ handlers.py                   # Alert handlers (email, webhook, etc)
â”‚   â””â”€â”€ notification_queue.py         # Notification queue
â”‚
â”œâ”€â”€ dashboard/                        # Web dashboards
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ streamlit_app.py              # Main Streamlit dashboard
â”‚   â”œâ”€â”€ pages/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ telemetry.py              # Telemetry dashboard
â”‚   â”‚   â”œâ”€â”€ evaluation.py             # Evaluation results
â”‚   â”‚   â”œâ”€â”€ performance.py            # Performance analytics
â”‚   â”‚   â”œâ”€â”€ agents.py                 # Agent registry view
â”‚   â”‚   â””â”€â”€ alerts.py                 # Alert management
â”‚   â””â”€â”€ components/
â”‚       â”œâ”€â”€ __init__.py
â”‚       â”œâ”€â”€ charts.py                 # Chart components
â”‚       â”œâ”€â”€ tables.py                 # Table components
â”‚       â””â”€â”€ filters.py                # Filter components
â”‚
â”œâ”€â”€ utils/                            # Utility modules
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ config.py                     # Configuration management
â”‚   â”œâ”€â”€ logging.py                    # Logging setup
â”‚   â”œâ”€â”€ validators.py                 # Data validation
â”‚   â””â”€â”€ helpers.py                    # Helper functions
â”‚
â””â”€â”€ examples/                         # Example usage
    â”œâ”€â”€ basic_monitoring.py           # Basic monitoring example
    â”œâ”€â”€ full_pipeline.py              # Full pipeline example
    â””â”€â”€ custom_evaluator.py           # Custom evaluator example
```

## ğŸš€ Quick Start

### Installation

```bash
cd agent_monitoring_platform
pip install -r requirements.txt
```

### Basic Usage

```python
from telemetry.collector import TelemetryCollector
from eval_pipeline.benchmark_suite import BenchmarkSuite

# Initialize telemetry
collector = TelemetryCollector()
collector.start()

# Define evaluation suite
suite = BenchmarkSuite()
suite.add_evaluator("quality", quality_evaluator)
suite.add_evaluator("performance", performance_evaluator)

# Run evaluation
results = suite.run()

# Stop telemetry and export data
collector.stop()
collector.export("telemetry.json")
```

### Run Dashboard

```bash
streamlit run dashboard/streamlit_app.py
```

## ğŸ”§ Core Components

### 1. Telemetry System

Captures real-time metrics from agent execution:

- **Agent Execution Traces**: Latency, input/output sizes, execution flow
- **LLM Metrics**: Token usage, API latency, cost tracking
- **System Metrics**: CPU, memory, disk I/O
- **Business Metrics**: User satisfaction, conversion rates, task completion
- **Error Tracking**: Exception rates, failure patterns, recovery times

### 2. Evaluation Pipeline

Automated evaluation framework:

- **Quality Metrics**: Accuracy, relevance, completeness, factuality
- **Performance Metrics**: Latency, throughput, resource utilization
- **User Experience**: Response time, error rate, retry rate
- **Regression Detection**: Compare against baseline versions
- **Multi-agent Comparison**: Benchmark across different models

### 3. Data Engineering

Production data infrastructure:

- **Data Models**: SQLAlchemy ORM for PostgreSQL/SQLite
- **ETL Pipeline**: Ingest, transform, load telemetry data
- **Analytics Engine**: Aggregations, time-series analysis, correlations
- **Data Export**: CSV, Parquet, API endpoints
- **Schema Management**: Auto-migration and versioning

### 4. Agent Registry

Centralized agent management:

- Agent metadata and capabilities
- Version tracking with rollback support
- Dependency management
- Configuration management

### 5. Alert System

Production monitoring alerts:

- Threshold-based alerts
- Anomaly detection
- Multiple notification channels
- Alert history and acknowledgment

## ğŸ“Š Supported Metrics

### Agent Execution Metrics
- Latency (min, max, avg, p50, p95, p99)
- Throughput (requests/sec)
- Error rate and error types
- Timeout rate
- Retry rate

### Quality Metrics
- Accuracy against ground truth
- Relevance scores
- Completeness checks
- Hallucination rate
- Citation accuracy

### Resource Metrics
- CPU usage
- Memory consumption
- Disk I/O
- Network bandwidth
- Cost per request

### Business Metrics
- User satisfaction scores
- Task completion rate
- User retention
- Feature adoption
- Revenue impact

## ğŸ”Œ Integrations

- **LLM APIs**: OpenAI, Groq, Anthropic, etc.
- **Message Queue**: Redis, RabbitMQ
- **Databases**: PostgreSQL, SQLite, DuckDB
- **Cloud Storage**: S3, GCS, Azure Blob
- **Monitoring**: Prometheus, Grafana
- **Alerting**: PagerDuty, Slack, Email

## ğŸ“ˆ Analytics Features

- Time-series analysis
- Correlation detection
- Anomaly detection
- Trend analysis
- Performance forecasting
- Comparative analysis

## ğŸ› ï¸ Configuration

See `utils/config.py` for all configuration options.

Key environment variables:
```bash
MONITORING_DB_URL=sqlite:///monitoring.db
MONITORING_LOG_LEVEL=INFO
MONITORING_EXPORT_INTERVAL=60
MONITORING_RETENTION_DAYS=90
```

## ğŸ“š Documentation

- `ARCHITECTURE.md` - Detailed system architecture
- `examples/` - Usage examples
- `dashboard/` - Dashboard documentation

## ğŸ” Security

- Sensitive data filtering (API keys, credentials)
- Data encryption at rest
- Role-based access control
- Audit logging
- Rate limiting

## ğŸ“ License

This project is part of the AI Voice Search Agent platform.

---

**For detailed architecture, see ARCHITECTURE.md**
